# Configuration
PYTHON = python3
ENV_NAME = mlops_env
REQUIREMENTS = requirements.txt

# Fichiers sources pour le CI/CD
PYTHON_FILES = model_pipeline.py main.py version_manager.py evaluate_with_scores.py
DATA_FILES = data/raw/churn-bigml-80.csv data/raw/churn-bigml-20.csv

.PHONY: setup install code-quality data train train-version evaluate evaluate-version scores list-versions clean help all ci-cd

.DEFAULT_GOAL := help

## üöÄ Installation des d√©pendances
setup:
	@echo "=== Cr√©ation de l'environnement virtuel ==="
	$(PYTHON) -m venv $(ENV_NAME)
	@echo "‚úÖ Environnement virtuel cr√©√©"
	@echo "=== Installation des d√©pendances depuis requirements.txt ==="
	@./$(ENV_NAME)/bin/pip install -r $(REQUIREMENTS)
	@echo "‚úÖ D√©pendances install√©es"

## üîç V√©rification du code
code-quality:
	@echo "=== Installation des outils de qualit√© de code ==="
	@./$(ENV_NAME)/bin/pip install black flake8 bandit
	@echo "=== Formatage automatique du code ==="
	@./$(ENV_NAME)/bin/black $(PYTHON_FILES)
	@echo "‚úÖ Code format√© avec Black"
	@echo "=== V√©rification de la qualit√© du code ==="
	@./$(ENV_NAME)/bin/flake8 $(PYTHON_FILES) --max-line-length=100 --ignore=E203,W503
	@echo "‚úÖ Qualit√© du code v√©rifi√©e avec Flake8"
	@echo "=== Analyse de s√©curit√© du code ==="
	@./$(ENV_NAME)/bin/bandit -r . -f html -o reports/security_report.html
	@echo "‚úÖ S√©curit√© analys√©e avec Bandit"

## üìä Pr√©paration des donn√©es
data:
	@echo "=== Pr√©paration des donn√©es ==="
	@./$(ENV_NAME)/bin/python main.py --prepare
	@echo "‚úÖ Donn√©es pr√©par√©es"

## ü§ñ Entra√Ænement du mod√®le
train:
	@echo "=== Entra√Ænement du mod√®le ==="
	@./$(ENV_NAME)/bin/python main.py --train
	@echo "‚úÖ Mod√®le entra√Æn√©"

## üè∑Ô∏è Entra√Ænement avec versionning
train-version:
	@echo "=== Entra√Ænement avec versionning ==="
	@./$(ENV_NAME)/bin/python -c "from version_manager import VersionManager; vm = VersionManager(); version = vm.get_next_version(); print(f'üéØ Utilisation de la version: {version}')"
	@./$(ENV_NAME)/bin/python main.py --train
	@./$(ENV_NAME)/bin/python -c "from version_manager import VersionManager; vm = VersionManager(); vm.save_current_version(); vm.create_version_snapshot(); print(f'‚úÖ Mod√®le version {vm.get_current_version()} sauvegard√© et versionn√©')"

## üìà √âvaluation du mod√®le
evaluate:
	@echo "=== √âvaluation du mod√®le ==="
	@./$(ENV_NAME)/bin/python main.py --evaluate
	@echo "‚úÖ Mod√®le √©valu√©"

## üéØ √âvaluation avec sauvegarde des scores
evaluate-version:
	@echo "=== √âvaluation avec scores ==="
	@./$(ENV_NAME)/bin/python evaluate_with_scores.py
	@echo "‚úÖ Scores sauvegard√©s"

## üìä Afficher les scores
scores:
	@echo "=== Scores par version ==="
	@./$(ENV_NAME)/bin/python -c "from version_manager import VersionManager; vm = VersionManager(); vm.show_scores()"

## üìã Lister les versions
list-versions:
	@echo "=== Versions disponibles ==="
	@./$(ENV_NAME)/bin/python -c "from version_manager import VersionManager; vm = VersionManager(); print(f'Version actuelle: {vm.get_current_version()}'); print('Versions:'); [print(f'  - {v}') for v in vm.list_versions()]"

## üß™ Tests
test:
	@echo "=== Tests ==="
	@mkdir -p reports
	@./$(ENV_NAME)/bin/python -c "import pandas as pd; import sklearn; print('‚úÖ Biblioth√®ques OK')" > reports/test_results.txt
	@./$(ENV_NAME)/bin/python -c "from model_pipeline import prepare_data, train_model; print('‚úÖ Modules OK')" >> reports/test_results.txt
	@./$(ENV_NAME)/bin/python -c "from version_manager import VersionManager; print('‚úÖ Version manager OK')" >> reports/test_results.txt
	@echo "‚úÖ Tests termin√©s - voir reports/test_results.txt"

## üîÑ CI/CD - Pipeline automatique
ci-cd: $(PYTHON_FILES) $(DATA_FILES)
	@echo "üöÄ D√âMARRAGE DU PIPELINE CI/CD"
	@echo "üìÅ Fichiers modifi√©s d√©tect√©s: $?"
	@date > reports/last_ci_cd.txt
	@echo "=== √âtape 1: Qualit√© du code ==="
	@$(MAKE) code-quality
	@echo "=== √âtape 2: Pr√©paration des donn√©es ==="
	@$(MAKE) data
	@echo "=== √âtape 3: Entra√Ænement avec versionning ==="
	@$(MAKE) train-version
	@echo "=== √âtape 4: √âvaluation avec scores ==="
	@$(MAKE) evaluate-version
	@echo "=== √âtape 5: Tests ==="
	@$(MAKE) test
	@echo "üéâ PIPELINE CI/CD TERMIN√â AVEC SUCC√àS"
	@echo "üìä Rapport g√©n√©r√©: reports/last_ci_cd.txt"

## üéØ Pipeline complet avec versionning
## üéØ Pipeline complet avec versionning
all: setup data train-version evaluate-version test
	@echo "=== TOUTES LES √âTAPES TERMIN√âES ==="
	@echo "‚úÖ Projet enti√®rement configur√© et pr√™t"

	
## üßπ Nettoyage
clean:
	@echo "=== Nettoyage ==="
	rm -rf models/*
	rm -rf reports/*
	rm -rf __pycache__
	rm -f *.pyc
	@echo "‚úÖ Fichiers g√©n√©r√©s nettoy√©s"

## üìã Aide
## üìã Aide
help:
	@echo "=== MAKEFILE - PR√âDICTION DE CHURN ==="
	@echo "Commandes disponibles:"
	@echo "  setup           - Cr√©er env virtuel + installer d√©pendances"
	@echo "  code-quality    - Formatage, qualit√©, s√©curit√© du code"
	@echo "  data            - Pr√©parer les donn√©es"
	@echo "  train           - Entra√Æner le mod√®le (simple)"
	@echo "  train-version   - Entra√Æner avec versionning automatique"
	@echo "  evaluate        - √âvaluer le mod√®le"
	@echo "  evaluate-version- √âvaluer et sauvegarder les scores"
	@echo "  scores          - Afficher les scores par version"
	@echo "  list-versions   - Lister les versions de mod√®les"
	@echo "  test            - Tests unitaires"
	@echo "  api             - D√©marrer l'API FastAPI"
	@echo "  api-prod        - API en mode production"
	@echo "  test-api        - Tester l'API"
	@echo "  ci-cd           - Pipeline CI/CD complet (automatique)"
	@echo "  all             - Tout ex√©cuter (setup + pipeline)"
	@echo "  clean           - Nettoyer les fichiers g√©n√©r√©s"
	@echo "  help            - Afficher cette aide"

## üöÄ API REST
api:
	@echo "=== D√©marrage de l'API FastAPI ==="
	@./$(ENV_NAME)/bin/uvicorn app:app --host 0.0.0.0 --port 8000 --reload

## üì° API en production
api-prod:
	@echo "=== D√©marrage de l'API en mode production ==="
	@./$(ENV_NAME)/bin/uvicorn app:app --host 0.0.0.0 --port 8000

## üß™ Test de l'API
test-api:
	@echo "=== Test de l'API ==="
	@./$(ENV_NAME)/bin/python -c "\
	import requests; \
	import time; \
	\
	# Attendre que l'API d√©marre \
	print('D√©marrage du test API...'); \
	time.sleep(2); \
	\
	# Test de sant√© \
	try: \
	    response = requests.get('http://localhost:8000/health'); \
	    print(f'‚úÖ Health check: {response.status_code}'); \
	    print(f'   R√©ponse: {response.json()}'); \
	except Exception as e: \
	    print(f'‚ùå Health check √©chou√©: {e}'); \
	\
	# Test des infos mod√®le \
	try: \
	    response = requests.get('http://localhost:8000/model-info'); \
	    print(f'‚úÖ Model info: {response.status_code}'); \
	    print(f'   Version: {response.json().get(\"version\", \"inconnue\")}'); \
	except Exception as e: \
	    print(f'‚ùå Model info √©chou√©: {e}'); \
	"

run:
	@echo "=== run container ==="
	@docker run -p 8000:8000 -p 8501:8501 mahdi-mlops

mlflow-ui:#mlflow ui --host 0.0.0.0 --port 5000 &
	@echo "=== run mlflow ui ==="
	@mlflow ui --host 0.0.0.0 --port 5000